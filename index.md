## Jack Griffiths     
## Deciphering Big Data, July-October 2024

---

### Home

### [Collaborateive Discussion 1](Discussion-Summary-1.pdf)
The first collaborative discussion focused on critically evaluating the rationale behind the Internet of Things (IoT), highlighting the opportunities, limitations, risks, and challenges in the context of large-scale processing of data.
I received feedback from other students on the course during the discussion period, which allowed me to further develop my initial post, with additional context added concerning IoT security, and mitigating the trade-off between accuracy and timliness when processing large amonts of real-time data.

### [Web Scraping Activity](Web-Scraping.md)
The web scraping activity made use of Python's BeautifulSoup library, which scrapes the HTML code from a specified webpage for use in data analysis. I was able to extract the HTML form University of Essex Online's data science course page, and count the number of times the phrase 'Data Science' appeared and recorded the results in a JSON file. I was able to compare my code with contributions in the module's Wiki page.

### [Data Cleaning Activity](Data-Cleaning.md)
The data cleaning activities were followed using pages xx to xx of the xxxx textbook. Data was downloaded from the UNICEF household survey data. Part of cleaning the data can involve making the set more human-readable. This allowed me to further practice using the Beautiful Soup library to scrape the human readable headings from the UNICEF website. The textbook continued to elaborate, with examples, how this is immplemented as well as further cleaning techniques for large data sets like these. Attached is the human readable table headings along with their corresponding codes, as well as the Python script used to scrape them.

### [Normalisation and Data Build Task](Normalisation-and-Build.md)
This task involved a random table displaying un-normalized data, which needed to be normalised using first normal, second normal, and third normal forms. This was initially done as a visual exercise using Excel, the .xlsx file is attached. 
A database was then built based on the data in third normal form with MySQL. The data was entered mostly manually, and in bulk by converting some tables in the Excel sheet to .csv. A .docx is attached explaining some of the queries used to test the referencial integrity of the data once it was inputted to the database.

### [Collaborative Discussion 2](https://github.com/crypto61/eportfolio/blob/master/Personal.md) 
The second collaborative discussion was centered around comparing the EU's GDPR with that of the UK, with a particular focus on security. The feedback I received on my initial post helped me to into further detail on the subtle differences between the two juristictions and improve my understanding on how GDPR works among the various member states. Through engaging with other students during the discussion, I provided feedback to peers highlighting the differences in compliance procedures thanks to the EU's one-stop shop mechanism, and learned about how GDPR works in non-EU country that also happens to be in the EEA country, such as Norway.

### [API Security Requirements](Professional.md)

### Module Reflection

---

---

Page template forked from [evanca](https://github.com/evanca/quick-portfolio)
